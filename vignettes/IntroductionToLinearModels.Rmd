---
title: "Introduction to Linear Models"
subtitle: "FGCZ Protein Informatics Training"
author: "Witold Wolski wew@fgcz.ethz.ch"
date: "2018-01-23"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "metropolis", "metropolis-fonts", "trug-ggplot2.css"]
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
editor_options:
  chunk_output_type: console
---

class: fullscreen, inverse, top, center, text-black
background-image: url("../inst/images/Linear_chair.jpg")

.font150[**linear models (lm)**]

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=4.25, fig.height=3.5, fig.retina=3,
                      message=FALSE, warning=FALSE, cache = TRUE,
                      autodep = TRUE, hiline=TRUE)
knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo <- FALSE
    options$out.height <- "99%"
    options$fig.width <- 16
    options$fig.height <- 8
  }
  options
})
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  if (!is.null(options$hiline) && options$hiline) {
    x <- stringr::str_replace(x, "^ ?(.+)\\s?#<<", "*\\1")
  }
  hook_source(x, options)
})
options(htmltools.dir.version = FALSE, width = 90)
as_table <- function(...) knitr::kable(..., format='html', digits = 3)

library(tidyverse)
```



---
# lm intro

.left-code[
```{r stripchart1, echo=TRUE, eval=FALSE}
dat <- read.csv("femaleMiceWeights.csv") ##previously downloaded
stripchart(Bodyweight ~ Diet, 
           data= dat, 
           vertical=TRUE, 
           method="jitter",
           main="Bodyweight over Diet")
```
]

.right-plot[
```{r stripchart1-out, ref.label="stripchart1", echo=FALSE, fig.width=6, fig.height=6}
```
]

---
# lm intro

.left-code[
```{r}
meansum <- 
  dat %>%
  group_by(Diet) %>%
  summarise(mean = mean(Bodyweight))
lm1 <- lm(Bodyweight ~ Diet,
          data = dat)
coefs <- coef(lm1)
```
]

.pull-right[
```{r  results='asis', echo=FALSE}
knitr::kable(meansum, format ="html", caption = "group means")
knitr::kable(coefs, format ="html", caption = "coefficients")
```
]

---

# lm Intro - examin the coefficients

.left-code[
```{r parameterEstimates, echo=TRUE , eval=FALSE}
stripchart(Bodyweight ~ Diet,
           data = dat , vertical=TRUE, method="jitter",
           main="Bodyweight over Diet", ylim=c(0,40), xlim=c(0,3))
a <- -0.25
lgth <- .1
library(RColorBrewer)
cols <- brewer.pal(3,"Dark2")
abline(h=0)
arrows(1+a,0,1+a,coefs[1],lwd=3,col=cols[1],length=lgth)
abline(h=coefs[1],col=cols[1])
arrows(2+a,coefs[1],2+a,coefs[1]+coefs[2],lwd=3,col=cols[2],length=lgth)
abline(h=coefs[1]+coefs[2],col=cols[2])
legend("right",names(coefs),fill=cols,cex=.75,bg="white")
```
]

.right-plot[
```{r parameterEstimates-out, ref.label="parameterEstimates", echo=FALSE, fig.width=6, fig.height=6}
```
]

---

# Introduction to linear models


.left-code[
```{r}
Y <- dat$Bodyweight
X <- model.matrix(lm1)
beta <- solve(t(X) %*% X) %*% t(X) %*% Y
c(t(beta)%*% t(X)[,1,drop=F],
t(beta)%*% t(X)[,13,drop=F])
epsilon <- Y - t(beta) %*% t(X)

```
]

.pull-right[
$$
\beta= (X^TX)^{âˆ’1} (X^TY)
$$

$\beta$ minimizes $$\sum(Y - \beta X)^2 = (Y-\beta X)(Y-\beta X)^T$$. 

predicting Y
$$\hat{Y} = X \beta$$

residues
$$r = Y - X\beta$$ 

]

---

# lm Intro - Contrasts

.left-code[
```{r}
linfct <- rbind(
  chow = c(1, 0),
  hf = c(1, 1 )
  )
linfct %*% coef(lm1)
```
]

.right-plot[
```{r parameterEstimates2-out, ref.label="parameterEstimates", echo=FALSE, fig.width=6, fig.height=6}
```
]


---

# lm Intro - Contrasts

.left-code[
```{r}
contrasts <- rbind(
  "chow - hf" = linfct["chow",] - linfct["hf",]
)
contrasts
contrasts %*% coef(lm1)

```
]

.right-plot[
```{r parameterEstimates3-out, ref.label="parameterEstimates", echo=FALSE, fig.width=6, fig.height=6}
```
]

---

# lm Intro -  LSE standard error

.left-code[

```{r}
e <- resid(lm1)
sigma <- sqrt(sum(e^2)/
                (length(e) -
                   length(coef(lm1))) )

X <- model.matrix(lm1)
solve(t(X) %*% X) * sigma^2
vcov(lm1)
```
]

.pull-left[
$$
\begin{aligned}
var(\hat{\beta}) &= var((X^\top X)^{-1}X^\top Y)\\
&= \cdots\\
&= \sigma^2 (X^\top X)^{-1}
\end{aligned}
$$
]

---

# lm Intro - computing the test statistic

```{r}
std.error <- sqrt(diag(linfct %*% vcov(lm1) %*% t(linfct)))
t.statistic <- linfct%*%coef(lm1)/std.error
t.statistic

std.error <- sqrt(diag(contrasts %*% vcov(lm1) %*% t(contrasts)))
t.statistic <- contrasts %*% coef(lm1) / std.error
t.statistic

```

---

# lm Intro - getting the p-values

.left-code[
```{r}
lfq <- 
  LFQService::my_contrast( lm1, #<
  rbind(linfct, contrasts)) %>% #<
  dplyr::select(lhs, estimate, std.error, statistic, p.value) %>%
  mutate(p.value = round(p.value,digits=3))

```
]


.pull-left[
```{r results="asis", echo=FALSE}
knitr::kable(lfq,format = "html" , caption ="LFQService",digits = 2)
```
]

---
# Multiple Hypothesis testing

.left-code[
```{r}
multcomp <- summary(
  glht(lm1, rbind(linfct, contrasts))) %>% #<
  broom::tidy() %>%
  dplyr::select(lhs, estimate, std.error, statistic , p.value) %>%
  mutate(p.value = round(p.value,digits=3))
```
]
  
  
.pull-left[
```{r results="asis", echo=FALSE}
knitr::kable(multcomp,results = "html", caption="multcomp")
```
]


# lm Intro - interactions


[genomicsclass](http://genomicsclass.github.io/book)



---

---
Briefly introduce linear models

Explain how the coefficients work give basic formulas for coefficients, coefficient variances

---
Discuss modelling of interactions

---
Discuss modelling of contrasts

explain that 
y_b = a + b
y_a = a
than y_b - y_a = (a+b)-a = b

---

# Modelling of proteomics data

- linear models
- mixed effect models
- Limma
- ROPECA
- msqRob
  - makes empirical bayes available for .

---

# Limma

- Limma (developed for genomics) employs empirical bayes
  - Empirical Bayes methods are procedures for statistical inference in which the prior distribution is estimated from the data.
  - Bayesian would start with a prior derived from pilot experiment or expert knowledge and update it using the data using the bayes rule.

- Advantage
  - Works for all types linear models.
- Disadvantage
  - You can't perform peptide level modelling directly - peptide measurements are correlated measures.
---

# Limma

- Get _posterior variance_ and _prior degrees of freedom_ based on variance distribution of all proteins
- update _t-statistic_, and degrees of freedom
- recompute _p.values_
  
  
```{r eval=FALSE}
sv <- squeezeVar(sigma^2, df=df.residual) #<< 
moderated.t <- tstat * sigma / sqrt(sv$var.post)
df.total <- df.residual + sv$df.prior   
p.value <- 2*pt( abs(moderated.t), df=df.total, lower.tail=FALSE)
```

.footnote[Smyth 2004, 2015]

---

# ROPECA

- Run Limma on peptide level
- aggregated peptide fold changes estimates e.g. median or mean

- estimate probability of differential expression



---



