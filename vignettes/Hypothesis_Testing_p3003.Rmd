---
title: "Hypothesis Testing"
subtitle: "FGCZ Protein Informatics Training"
author: "Witold Wolski wew@fgcz.ethz.ch"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "metropolis", "metropolis-fonts", "trug-ggplot2.css"]
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
editor_options:
  chunk_output_type: console
vignette: >
  %\VignetteIndexEntry{Hypothesis Testing} 
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
  
---

class: fullscreen, inverse, top, center, text-black
background-image: url("../inst/images/test_chair.jpeg")

.font150[**hypothesis testing**]

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=4.25, fig.height=3.5, fig.retina=3,
                      message=FALSE, warning=FALSE, cache = TRUE,
                      autodep = TRUE, hiline=TRUE)
knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo <- FALSE
    options$out.height <- "99%"
    options$fig.width <- 16
    options$fig.height <- 8
  }
  options
})
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  if (!is.null(options$hiline) && options$hiline) {
    x <- stringr::str_replace(x, "^ ?(.+)\\s?#<<", "*\\1")
  }
  hook_source(x, options)
})
options(htmltools.dir.version = FALSE, width = 90)
as_table <- function(...) knitr::kable(..., format='html', digits = 3)

library(tidyverse)
```

---

# Introduction

- What is a hypothesis and how it can be tested
- What is a test statistic
- how to generate the distribution of the test statistic if null true
- one sample t-test
- what happens if assumptions are not met
- central limit theorem
- assymptotic tests
- non parametric tests - randomization test
- comparing parametric, non parametric and assymptotic tests
- paired t-test
- equivalence of t-test and linear models

---

#  Lady tasting tea

Dr. Muriel Bristol, a female colleague of Fisher claimed to be able to tell whether the tea or the milk was added first to a cup.

--

- The null hypothesis was that the Lady had no such ability.
--

- The test statistic was a simple count of the number of successes<br/> in selecting the 4 cups out of 8.

--
- What was the probability of getting the number she got correct (all correct)?

---

# Lady tasting tea

.left-code[
```{r teatasting, eval = FALSE}
truth <- c(0,1,0,1,1,0,0,1)
x <- combn(truth,4) #<<
nrcor <- apply(x, 2, sum) #<<
nulldistr <- table(nrcor)

plot(nulldistr, xlab="nr correct")
```
]


.right-plot[
```{r teatasting-out, ref.label="teatasting", echo=FALSE,  out.width="100%"}
```
]

---
# Lady tasting tea

```{r}
probs <- nulldistr / sum(nulldistr) # compute probabilities
probs <- round(probs, digits=3)
probs
```

Hence, on $\alpha = 0.05$ reject since getting 4 right is $P(x = 4) = `r probs[5]`$ 

If she would have 3 right would you accept the null hypothesis?

--

$P(x > 3) = `r probs[5]` + `r probs[4]` = `r probs[5] +  probs[4]`$.


---
layout: false

# Hypothesis testing - Brief version

- __State research hypothesis__
- State Relevant Null and Alternative hypothesis
- Define test (T) statistic. 
- Determine distribution of the test statistic<br/> under null hypothesis
- Define Critical region.
- Check if $T_{obs}$ is within the critical region.




```{r hypo-explained, eval=FALSE, echo = FALSE}
# Plot distribution of T under null Hypothesis
x <- seq(-3,5, by=0.1)
plot(x, dnorm(x), type="l", xlim = c(-3,5))

# Specify alpha and show critical regions
alpha <- 0.05
crl <- qnorm(alpha/2)
crh <- qnorm(1 - alpha/2)
abline(h = 0)
abline(v = c(crl, crh), col=2)

text(  2.1 , 0.1, "critical region", adj=0, srt=90)
text( -2.1 , 0.3, "critical region", adj=0, srt=-90)

# Show not significant test statistic
abline(v = 1.2, col=3)
text(1.2, 0.1, expression(t[obs]), srt=90)

# Show significant test statistic
abline(v = 4, col="magenta")
text(4, 0.1, expression(t[obs]), srt=90)

```


.img-right[
```{r hypo-explained-out, ref.label="hypo-explained", echo=FALSE, fig.width=6, fig.height=6}
```
]

---

# Hypothesis testing - Long version

- State the relevant null and alternative hypotheses. _This is important, as mis-stating the hypotheses will muddy the rest of the process._
- Consider the statistical assumptions being made about the sample. _e.g., statistical independence, distributions of the observations. invalid assumptions will mean that the results of the test are invalid._
- State the relevant test statistic T (Decide which test is appropriate).
- Derive the distribution of the test statistic under the null hypothesis. _e.g., the test statistic follow's a Student's t distribution_
- Select a significance level $\alpha$, which defines the critical region of null distribution.
- Compute from the observations the observed value $t_{obs}$ of the test statistic T.
- Reject the null hypothesis if the observed value $t_{obs}$ is in the critical region.


---

# Testing if mean is equal to $\mu$

- Hypothesis - mean of sample is different than some value $\mu$.
- What is the null and what is the alternative?
--

  - Null is that the mean of observed data is equal to $\mu$.
  - Alternative - it is NOT equal to $\mu$.
- What is the distribution of the observations?
--
  
  - Observations are independent, identically distributed (iid)
  - $x \sim N(\mu, \sigma)$.
- State the relevant test statistic T?
--

  - A suitable test statistics $\bar{X} - \mu$.
- What is the distribution of T under the null hypothesis?
--

  - It will depend on samples size $n$ and on the variance $\sigma^2$


---

#  mean is equal to $\mu$? Simulate data under null


.left-code[


```{r, include=FALSE}
decimalplaces <- function(x) {
    if (abs(x - round(x)) > .Machine$double.eps^0.5) {
        nchar(strsplit(sub('0+$', '', as.character(x)), ".", fixed = TRUE)[[1]][[2]])
    } else {
        return(0)
    }
}

getBreaks <- function(T0,by=0.1){
  res <- seq(round(min(T0), digits = decimalplaces(by))-by,round(max(T0), digits = decimalplaces(by))+by, by=by)
  return(res)
}


```

```{r simulateData, eval=FALSE}
# Simulating data from Null
N <- 1000; N_obs <- 4;
mu <- 0; sigma <- 1
bb <- function(y){
  x <- rnorm( N_obs, mu, sigma )
  data.frame(mean = mean( x ),
             sd = sd(x)) 
}
res <- purrr::map_df(1:N, bb)
res %>% tidyr::gather() %>%
ggplot(aes(x = value)) +
  geom_histogram() +
  facet_grid(~key)
```
]


.right-plot[
```{r simulateData-out, ref.label="simulateData", echo=FALSE,  out.width="100%"}
```
]


---

# Mean = $\mu$? What is the distribution of T under null?

.left-code[
if $\sigma$ known

```{r simulatingH0SigmaK, eval=FALSE, size="footnotesize"}
T0 <- mu - res$mean
hist(T0, 
     breaks=getBreaks(T0, by=0.05),
     probability = T,
     main="")
x <- seq(-10,10,0.01)
lines(x, 
      dnorm(x,
            sd= (sigma/sqrt(N_obs))), #<<
      col=2)

```

$T|H_0 \sim N(0,\sigma/\sqrt(N_{obs}))$

]

.right-plot[
```{r simulatingH0SigmaK-out, ref.label="simulatingH0SigmaK", echo=FALSE, out.width="100%"}
```
]



---

# Improved test statistic T*

The __t-statistic__

$$T = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}$$
Z- transformed data $\sim WN(0,1)$.

The variance of the sampling distribution of the mean is the population variance divided by $n$ (given $iid$ data).

$$\sigma^2_{mean} = \sigma^2/n$$

---

# Mean = $\mu$? What is the distribution of T*?

.left-code[
if $\sigma$ known

```{r simulatingH0SigmaKTnew, eval=FALSE, size="footnotesize"}
T0 <- (mu - res$mean)/
  (sigma/sqrt(N_obs)) #<<
hist(T0, 
     breaks=getBreaks(T0, by=0.05),
     probability = T,
     main="")
x <- seq(-10,10,0.01)
lines(x, 
      dnorm(x, 
            sd= 1), #<<
      col=2)
```

$T|H_0 \sim N(0,1)$
]

.right-plot[
```{r simulatingH0SigmaKTnew-out, ref.label="simulatingH0SigmaKTnew", echo=FALSE, out.width="100%"}
```
]

---

# Mean = $\mu$? Unknown Variance

.left-code[
if $\sigma$ UNKNOWN
```{r simulatingH0SigmaUK, eval = FALSE}
T0 <- (mu - res$mean) /
  (res$sd/sqrt(N_obs)) #<<
hist(T0,
     breaks=getBreaks(T0),
     probability = T, xlim=c(-6,6),
     ylim=c(0,0.4),main="")
x <- seq(-10,10,0.1)
lines(x, dnorm(x),#<<
      col="red")
lines(x,dt(x,df = N_obs), #<<
      type="l",col="green",lwd=2)

```

$T|H_0 \sim T(\mu=0,df=N_{obs})$

]


.right-plot[
```{r simulatingH0SigmaUK-out, ref.label="simulatingH0SigmaUK", echo=FALSE, out.width="100%"}
```
]

---

# Mean = $\mu$? $x \sim Exp(1)$

.left-code[

```{r simulatingH0withWrongAssumptions, eval=FALSE}
N <- 10000;rate <- 1;
N_obs <- 4;
bb_exp <- function(y){
  x <- rexp( N_obs, rate=rate )-1 #<<
  data.frame(mean = mean( x ),
             sd = sd(x)) 
  }
res <- purrr::map_df(1:N, bb_exp)
T0 <- (res$mean - mu)/ #<<
  (res$sd/sqrt(N_obs)) #<<
hist(T0, breaks=getBreaks(T0),
     probability = T, xlim=c(-6,6),
     ylim=c(0,0.4), main="")
lines(x,
      dt(x,df = N_obs), #<<
      type="l",col="green",lwd=2)
```
]


.right-plot[
```{r simulatingH0withWrongAssumptions-out, ref.label="simulatingH0withWrongAssumptions", echo=FALSE, out.width="100%"}
```
]

.footnote[Assumption is that $x$ is generated using a normal distribution. But this time we simulate $4$ datapoints from an exponential distribution.]


---

# Mean = $\mu$? $x \sim Exp(1)$  with $N_{obs} = 40$

.left-code[

```{r simulatingH0withWrongAssumptionsN12, eval=FALSE}
# Simulating data from Null
N <- 10000;rate <- 1
N_obs <- 40 #<<
bb_exp <- function(y){
  x <- rexp( N_obs, rate=rate )-1
  data.frame(mean = mean( x ), sd = sd(x)) 
}
res <- purrr::map_df(1:N, bb_exp)
T0 <- res$mean/
  (res$sd/sqrt(N_obs))
hist(T0, breaks=getBreaks(T0),
     probability = T,   xlim=c(-6,6),
     ylim=c(0,0.4), main="")
lines(x,dt(x,df = N_obs),type="l",
      col="green",lwd=2)
```
]


.right-plot[
```{r simulatingH0withWrongAssumptionsN12-out, ref.label="simulatingH0withWrongAssumptionsN12", echo=FALSE}
```
]

.footnote[Assumption is that $x$ is generated using a normal distribution. But this time we simulate $40$ datapoints from an exponential distribution.]


---

# Mean = $\mu$? $x \sim Exp(1)$ but with $N_obs = 100$

.left-code[

```{r simulatingH0withWrongAssumptionsN100, eval=FALSE}
# Simulating data from Null
N <- 10000;rate <- 1
N_obs <- 100 #<<
bb_exp <- function(y){
  x <- rexp( N_obs, rate=rate )-1
  data.frame(mean = mean( x ), sd = sd(x)) 
}
res <- purrr::map_df(1:N, bb_exp)
T0 <- res$mean/
  (res$sd/sqrt(N_obs))
hist(T0, breaks=getBreaks(T0),
     probability = T, xlim=c(-6,6),
     ylim=c(0,0.4), main="")
lines(x,dt(x,df = N_obs),type="l",
      col="green",lwd=2)
```
]


.right-plot[
```{r simulatingH0withWrongAssumptionsN100-out, ref.label="simulatingH0withWrongAssumptionsN100", echo=FALSE}
```
]

.footnote[Assumption is that $x$ is generated using a normal distribution. But this time we simulate $100$ datapoints from an exponential distribution.]

---

# Central Limit Theorem

- In probability theory, the __central limit theorem__ (CLT) establishes that, in some situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a "bell curve") even if the original variables themselves are not normally distributed. 

--

- The theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.

--

- Some methods rely on __asymptotic properties__  (e.g. `multomp` p-value compua)

---

# Types of tests

- parametric tests e.g. t-test 
  - assume underlying statistical distributions in the data. 
  - Therefore, several conditions of validity must be met so that the result of a parametric test is reliable.
  - For example, Studentâ€™s $t-test$ for two independent samples is reliable only if each sample follows a normal distribution and if sample variances are homogeneous.  
--

- asymptotic tests
   - assume that methods which work for normal distributions work also elsewhere
--

- nonparametric tests e.g. randomization test
   - do not rely on any distribution. They can thus be applied even if parametric conditions of validity are not met. 
   - Parametric tests __often__ have nonparametric equivalents. 


---

# Two sample t-test

There is a difference between the means of two samples.

- Null hypothesis - there is no such difference

- Test statistic:

$T = \frac{Y_1 - Y_2}{\sqrt{\frac{s_1^2}{N_1} + \frac{s_2^2}{N_2}}}$

- Significance level $\alpha$

- Reject the null hypothesis that the two means are equal if $|T| > t_{1-\alpha/2,v}$ with $v$ degrees of freedom 

$\upsilon = \frac{(s^{2}_{1}/N_{1} + s^{2}_{2}/N_{2})^{2}} {(s^{2}_{1}/N_{1})^{2}/(N_{1}-1) + (s^{2}_{2}/N_{2})^{2}/(N_{2}-1) }$

---


# Randomization tests

1. Suppose the 10 individuals in the study have been labelled


```{r echo=FALSE}
tmp <- list("Diet A"=as.integer(c( 1, 2, 3, 4, 5)),
            "Diet B" = as.integer(c( 6, 7, 8 , 9, 10)))

library(flextable)
tmp <- (data.frame(tmp))

tmp %>%
  head() %>%
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  flextable()

```

2. Randomly re-assign the 10 individuals to the two groups.
3. Re-calculate the test-statistic for this permuted data
4. Repeat 2 and 3 to obtain $B$ sampled test-statistics, denoted
$T_1, \dots, T_B$.
5. For a two-sided test, the estimated p-value of the observed
test statistic $T_{obs}$ is:

$$\frac{1}{B} \sum^B_{i=0} I_{T_i} >= |T_{obs}|$$

.footnote[Step 1-3 generates a sample from the null distribution.]
---

```{r fun_def, echo=FALSE, include=FALSE}

```

# Compare tests

.pull-left[

- Simulate data from <br/> $x_1 \sim N(0,1)$ and $x_2\sim N(1.3,1.3)$ <br/> (10 each)
- compute p-values using:
  - randomization test
  - t-test
  - asymptotic test <br/> (T under null $\sim N(\mu, \sigma)$)


```{r randomization_test, eval=FALSE, echo=FALSE}
dist1 <- function(N){rnorm(N, 0, 1 )}
dist2 <- function(N){rnorm(N, 1.3,1.3)}

xx <- p3003PBC::sample_stats(N=10,
                   dist1,
                   dist2,
                   samples = 100)

par(mfrow=c(2,1))

plot(xx$res_p[,"coin"], xx$res_p[,"t.test"], log="xy", ylab="log(p.value) t.test", xlab="log(p.value) randomization test", pch=16,cex=0.5)
abline(c(0,1), col="blue")
abline(h=0.01,v=0.01, col="gray")

plot(xx$res_p[,"asymp.test"], xx$res_p[,"t.test"], log="xy",  xlab="log(p.value) asymptotic test",ylab="log(p.value) t.test", pch=16,cex=0.5)
abline(c(0,1), col="blue")
abline(h=0.01,v=0.01, col="gray")

```
]


.right-plot[
```{r randomization_test-out, ref.label="randomization_test", echo=FALSE, fig.width=6, fig.height=8}
```
]

---

# Compare tests

```{r}
cbind( coin = table(xx$res_p[,"coin"] < 0.01),
t.test = table(xx$res_p[,"t.test"] < 0.01),
asymp.test = table(xx$res_p[,"asymp.test"] < 0.01)) -> x
rownames(x) <- c("Accept", "Reject H0")
knitr::kable(x, format="html")
```

---

# Repeated - correlated measurements

.left-code[
```{r corMeasures, eval=FALSE}
old_mar <- par()$mar
par(mfrow=c(3,1), mar=c(4,4,0,0))
plot(extra ~ group, data = sleep) #<<
sleep %>% tidyr::spread(group, extra) -> 
  sleepwide
colnames(sleepwide) <- make.names(
  colnames(sleepwide)
  )
plot( sleepwide$X1, sleepwide$X2) #<<
legend("topleft", legend = 
       paste("cor = ",
       round(
         cor(sleepwide$X1, sleepwide$X2),
         digits=2)))
sleepwide <- sleepwide %>% 
  dplyr::mutate(diff = X2-X1) 
boxplot(sleepwide$diff) #<<
par(mar = old_mar)

```
]

.right-plot[
```{r corMeasures-out , ref.label="corMeasures", echo=FALSE, fig.width=6, fig.height=6}
```
]

.footnote[To see `sleep` dataset documentation run `?sleep` in R.]


---

# Repeated - correlated measurements

- test-statistics two groups

$$t_{unpaired} = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{s^2(\frac{1}{n_1} + \frac{1}{n_2})}}$$


- test-statistics paired

$$t_{paired} = \frac{\bar{d}}{\frac{s_d}{\sqrt{n}}}$$

with $\bar{d}$ the mean of the differences $d_i$ with $i \in (1,\dots, n)$, and $d_i = x_{2i} - x_{1i}$ (the correlated samples in condtion $1$ and $2$).
---


# Repeated - correlated measurements

.left-code[
```{r}
test.p.values <- data.frame(
unpaired.p = 
  t.test(extra ~ group,#<<
         data = sleep,#<<
         paired = FALSE)$p.value, #<<
paired.p = 
  t.test(extra~group,#<<
         data = sleep, #<<
         paired = TRUE)$p.value, #<<
diff.p = 
  t.test(sleepwide$diff)$p.value #<<
)

```

.footnote[Top code block - two sample t-test, middle code block - paired t-test, bottom code - one sample t.test on differences. Note that the paired t-test gives the same results as the one sample t.test of differences]
]

.pull-right[
```{r  results='asis', echo=FALSE}
knitr::kable(signif(test.p.values, digits=2), format="html")
```

]

---

# Missing data

```{r}
sleepless <- datasets::sleep
sleepless$extra[c(1,4,6,12)] <- NA
sleepless$extra[1:4]
tryCatch(
  t.test(extra ~ group, data = sleepless, paired =TRUE),#<<
  error = function(e) e)
```

.footnote[running the paired t-test with missing data fails.]

---

# Linear models

.left-code[
```{r}
lm1 <- lm(extra ~ group, data = sleep) #<<
lm2 <- lm(extra ~ group + ID, data = sleep) #<<
lmermod <- 
  lmerTest::lmer(extra ~ group + (1|ID),
                 data = sleep) #<<


x <- bind_rows(
broom::tidy(anova(lm1))[1,],
broom::tidy(anova(lm2))[1,],
broom::tidy(anova(lmermod))[1,],
)

xx <- add_column(x, model = 
        c("lm_1","lm_2","lmer"),
        .before = 1) %>%
  dplyr::select(model, p.value) %>%
  mutate(p.value = signif(p.value, digits=2))
  
```
]

.pull-right[
```{r  results='asis', echo=FALSE}
knitr::kable(xx, format="html")
```
]

.footnote[performing the same t-tests but using linear models and mixed effect linear models produces same result.]

---

# Linear models - missing data


.left-code[
```{r}
lm1 <- lm(extra ~ group, #<<
          data = sleepless) #<<
lm2 <- lm(extra ~ group + ID, #<<
          data = sleepless) #<<
lmermod <- lmerTest::lmer( #<<
  extra ~ group + (1|ID), #<<
  data = sleepless) #<<
x <- bind_rows(
broom::tidy(anova(lm1))[1,],
broom::tidy(anova(lm2))[1,],
broom::tidy(anova(lmermod))[1,],
)

xx <- add_column(x, 
        model = c("lm_1","lm_2","lmer"),
        .before = 1) %>%
  dplyr::select(model, p.value) %>%
  mutate(p.value = signif(p.value, digits=2))
```
]


.pull-right[
```{r  results='asis', echo=FALSE}
knitr::kable(xx, format="html")
```
]

.footnote[Linear models do work also with missing data.]
---


# Conclusion

- If assumptions in parametric tests are not met null distribution is wrong, hence p-value
- parametric tests do not make assumptions about the data
- there might be no non-parametric alternative to a parametric test
- Understand CLT and what assymptotic properties are
- Asymptotic properties are sometimes used to derive null distributions for complex models. If this is the case and your sample sizes are small be carefull.


