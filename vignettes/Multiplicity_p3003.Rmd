---
title: "Multiple Testing"
subtitle: "FGCZ Protein Informatics Training"
author: "Witold Wolski wew@fgcz.ethz.ch"
date: "2018-10-21"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "metropolis", "metropolis-fonts", "trug-ggplot2.css"]
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
editor_options:
  chunk_output_type: console
---

class: fullscreen, inverse, top, center, text-white
background-image: url("../inst/images/many-black-chair-backs.jpg")

.font150[**Multiplicity**]

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=4.25, fig.height=3.5, fig.retina=3,
                      message=FALSE, warning=FALSE, cache = TRUE,
                      autodep = TRUE, hiline=TRUE)
knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo <- FALSE
    options$out.height <- "99%"
    options$fig.width <- 16
    options$fig.height <- 8
  }
  options
})
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  if (!is.null(options$hiline) && options$hiline) {
    x <- stringr::str_replace(x, "^ ?(.+)\\s?#<<", "*\\1")
  }
  hook_source(x, options)
})
options(htmltools.dir.version = FALSE, width = 90)
as_table <- function(...) knitr::kable(..., format='html', digits = 3)

library(tidyverse)
```

---
layout: false

# Weight loss example

Experiment:
- 250 subjects chosen "randomly".
- Diet for 1 week.
- Repeated Measurement (Data in kg.):
   - Weight at the start of the week
   - Weight at the end of week. 

Average weight loss is $0.13$kg. Paired t-test for weight <br/>
loss gives a t-statistic of $t=0.126/0.068=1.84$,</br>
giving a p-value of $0.067$ (using a two-sided test).</br>
Not quite significant at the $5%$ level!


.img-right[
![](../inst/images/Multi_Test_Weight_example_1.png)
]

.footnote[Example from  Andersen (1990) ]

---

# Weight loss example

.left-code[

```{r}
2*(1- pt(1.84, df = 250-1))
2*(1- pnorm(1.84, 0,1))#<<
(1 - pt(1.84, df = 250-1)) #<<
```
assymptotic tests - does not "help" (and is biased).<br/>
1-sided test is not acceptable!
Why?
]

.right-plot[
![](../inst/images/Multi_Test_Weight_example_1.png)
]

.footnote[Example from  Andersen (1990) ]
---
layout: false

# Weight loss example

Can anything be done to get a significant result</br>
out of this study?</br>
--

_How about introducing additional factor?_</br>
--

Look at subgroups of the data by their sign of the Zodiac.</br>
--


- Conclusions: those born under the sign of Aries</br> are particularly suited to this new dietary control.


.img-right[
![](../inst/images/Multi_Test_Weight_example_2.png)
]

---

# Weight loss example


What is the problem of this approach?

--

Hypothesis that Aireans are good dieters
was only suggested by the data and the fact that it gave an apparently significant
result.


- What difference would it make if you designed your experiment with that hypothesis in mind?
--

  - Plausibility - possible biological mechanism which suggest the hypothesis.
  - You would test this hypothesis and compare it with a control group.
  

---

# Where does multiplicity arise

- __Multiple endpoints__
  - many outcome measures to asses an intervention. <br/>
  In mass spectrometry: _MS1 intensity and MS2 intensity (DIA)_.
  - Solution : ajdust p-values, choose primary outcome, multivariate analysis.
--

- __Interim Analysis__
  - analyze the data from a trial _periodically_ as it becomes available
  - Solution: adjust p-values

---

# Where does multiplicity arise


- __Subgroup comparison__
  - sample is subdivided on baseline factors : gender, age-groups, sign of zodiac
  - Solution : adjust p-values, Anova
- __Repeated measures__
  - e.g. blood concentration of some metabolite at baseline and then at intervals of 1, 3, 6, 12 and 24 hours after ingestion of a drug. <br/>
  Use two-sample t-tests on the measures at each time point in sequence.
  - Solution: adjust p.value, use summary measure (e.g. fit line and test line coefficients), Multivariate analysis  
- __Multiple Regression__
  - regression analyses involving many explanatory variables
  - Solution: Use background knowledge to suggest possible models, include only few interaction terms, adjust p-values. 

---

# P-value adjustment - Bonferroni correction

If multiple hypotheses are tested, the chance of a rare event increases, and therefore, the likelihood of incorrectly rejecting a null hypothesis (i.e., making a Type I error) increases.

The Bonferroni correction compensates for that increase by testing each individual hypothesis at a significance level of $\epsilon = \alpha /k$, $\alpha$  is the desired overall alpha level and $k$ is the number of hypotheses.

$$k=20; \alpha = 0.05,\epsilon = 0.05/20 = 0.0025$$


Bonferroni adjustments are typically very conservative (because in many situations the tests are highly correlated) and more complex methods are usually used.
In R use `p.adjust` which transforms the p-values instead transforming the threshold.

.footnote[wikipedia, Medical Statistics - Sheffield University 2018] 

---

# P-value adjustment - Bonferroni correction

FamilyWise Error Rate (FWER) - control the probability of at least one Type I error
Maths for Bonferroni
$$
\begin{align}
Pr(at~least~one_Type~I~error|H_0) = \epsilon &=  1 - Pr(no~rejections|H_0)\\
&= 1- \prod^k Pr(p_i > \alpha)\\
&= 1- \prod^k (1-\alpha)\\
&= 1-(1-\alpha)^k
\end{align}
$$
Solving for $\alpha$ gives approx $$\epsilon = \alpha/k$$ or exact result $$\epsilon = 1- \exp(1/k\log(1-\alpha))$$.


.footnote[http://genomicsclass.github.io/book/pages/multiple_testing.html]
---

# P-value adjustment - package `multcomp`

.left-code[
Model with NO interactions
```{r}
lmod <- lm(Fertility ~ ., #<<
           data = swiss)
lmtable <- broom::tidy(summary(lmod))
K <- diag(length(coef(lmod)))[-1,] #<<
rownames(K) <- names(coef(lmod))[-1] #<<
adjusted <- broom::tidy(summary( 
  multcomp::glht(lmod, linfct = K))) #<<
comp <- inner_join(lmtable[-1,-c(2,3,4)],adjusted[-c(2,3,4,5)], by=c("term"="lhs"))
colnames(comp)[c(2,3)] <- c("p.value","p.adjusted")
```
]


.pull-right[
```{r  results='asis', echo=FALSE}
knitr::kable(comp, format="html", caption="compare p.value and adjusted p.value")
```
]

.footnote[multcomp: Simultaneous Inference in General Parametric Models by _Torsten Hothorn_, <br/>Mathematics and theory complex, uses assymptotic properties to make it tractable ]

---
# Multiplicity conclusion (FWER)

Multiplicity adjustment will demand a unrealistically
small p-value. 

In practice there are better ways of overcoming the problem
of multiplicity, 
- by limiting the number of tests (Test only 1 maximum 2 hypothesis)
- by concentrating on the more important objectives
- using a more sophisticated analysis (e.g. fitting time courses)
- in the discovery fase using _False Discovery Rate_ instead of _Family Wise Error Rates_.


---

# False Discovery Rate (FDR)

FDR-controlling procedures are designed to control the expected proportion of "discoveries" (rejected null hypotheses) that are false (incorrect rejections).
Particularily usefull in the discovery fase where even FDR's of up to 50% are feasible.

```{r results='asis', echo=FALSE}
table <- data.frame( c("Reject H0","Accept H0", "Total"), matrix(c("V (FP)","S (TP)","R","U (TN)","T (FN)","m-R","m_0","m-m_0","m"), ncol=3, byrow=T))
colnames(table) <- c("R/C","H0 TRUE", "HA", "Total")
knitr::kable(table, format="html")
```

the proportion of false discoveries among the discoveries (rejections of the null hypothesis)

$Q=V/R=V/(V+S); ~~~ where ~~~ Q=0 ~~if~~R=0$<br/>
$FDR = Q_e = E[Q]$ (expected value of $Q$).


.footnote[https://en.wikipedia.org/wiki/False_discovery_rate, Benjamini-Hochberg (1995)]
---

# FDR and p-value distribution

.img-right[
![](../inst/images/Multitest_pValue_FDR_Estimation.png)
]

.footnote[John D.Storey 2002; Storey and Tibshirani 2003; Prummer 2012]

---


# FDR - Benjamini Hochberg - procedure

For any given FDR level $\alpha$,
the Benjamini-Hochberg (1995) procedure is very practical<br/> because it simply requires that we are able to compute p-values for each of the individual tests and this permits a procedure to be defined.


We list these p-values in ascending order and denote them by $P_{(1)} \ldots P_{(m)}$.

For a given FDR level $\alpha$, find the largest $k$ such that $P_{(k)} \le \frac{k}{m}\alpha$.

Reject the null hypothesis (i.e., declare discoveries) for all $H_{(i)}$ for $i = 1, \ldots, k$.


---

# FDR - Benjamini Hochberg - procedure



.left-code[
```{r echo=FALSE}
m <- 1000
delta <- 2
pvals <- sapply(1:m, function(i){
  control <- rnorm(6,0,1)
  treatment <- rnorm(6,0,1)
  if(runif(1) < 0.1){
   treatment <- treatment + delta
  }  
  t.test(treatment,control)$p.value
  })
```

```{r BHprocedure, eval=FALSE, echo=TRUE}
alpha <- 0.05
i = seq(along=pvals)
k <- max(which(sort(pvals) < i/m*alpha)) #<<
padj <- p.adjust(pvals,method="BH") #<<

par(mfrow=c(2,2))
hist(pvals, breaks=20)
hist(padj , breaks = 20)
plot(i,sort(pvals))
abline(0,i/m*alpha, col=2)
plot(i[1:30],sort(pvals)[1:30],type="b",main="Close-up")
abline(0,i/m*alpha, col=2)

```
]



.right-plot[
```{r BHprocedure-out, ref.label="BHprocedure", echo=FALSE, fig.width=6, fig.height=6}
```
]

---
# FDR - Benjamini Hochberg - procedure
.right-code[
```{r}
p.adjust.BH <- function (p,  n = length(p))
{
  nm <- names(p)
  p <- as.numeric(p)
  p0 <- setNames(p, nm)
  if (all(nna <- !is.na(p)))
    nna <- TRUE
  p <- p[nna]
  lp <- length(p)
  stopifnot(n >= lp)
  if (n <= 1) return(p0)
  i <- lp:1L
  o <- order(p, decreasing = TRUE)
  ro <- order(o)
  p0[nna] <-  pmin(1, cummin(n/i * p[o]))[ro]
  return(p0)
}
```
]

---

# FDR - Conclusion

- $FDR \le 0.05$ is a much more lenient requirement then $FWER \le 0.05$.

Although we will end up with more false positives, FDR gives us much more power. This makes it particularly appropriate for discovery phase experiments where we may accept FDR levels much higher than 0.05.

The BH procedure is valid when the m tests are independent, and also in various scenarios of dependence, but is __not universally valid__. (e.g. gene sets.)

---

# Possible p-value distributions


[How to interpret a p-value histogram](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/)


---

# Conclusion - Take home message

- _Family Wise Error Rates (FWER)_  - use to adjust for number of tests for single protein.
  - better - limit the number of tests
- _False Discovery Rate (FDR)_ - control error rates when selecting proteins for follow up in discovery phase



