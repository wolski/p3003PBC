---
title: "Experimental Design"
subtitle: "FGCZ Protein Informatics Training"
author: "Witold Wolski wew@fgcz.ethz.ch"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "metropolis", "metropolis-fonts", "trug-ggplot2.css"]
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
editor_options:
  chunk_output_type: console
vignette: >
  %\VignetteIndexEntry{Experimental Design} 
  %\VignetteEncoding{UTF-8}
  
  %\VignetteEngine{knitr::rmarkdown}
---

class: fullscreen, inverse, top, center, text-black
background-image: url("../inst/images/Linear_chair.jpg")

.font150[**design**]

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 4.25,
                      fig.height = 3.5,
                      fig.retina = 3,
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE,
                      autodep = TRUE,
                      hiline = TRUE)

knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo <- FALSE
    options$out.height <- "99%"
    options$fig.width <- 16
    options$fig.height <- 8
  }
  options
})
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  if (!is.null(options$hiline) && options$hiline) {
    x <- stringr::str_replace(x, "^ ?(.+)\\s?#<<", "*\\1")
  }
  hook_source(x, options)
})
options(htmltools.dir.version = FALSE, width = 90)
as_table <- function(...) knitr::kable(..., format='html', digits = 3)
```


---

exclude: true

# LFQ a success story


--
exclude: true

- Novel aquisition methods (DIA vs DDA)

.img-right[
![](../inst/images/DIA_vs_LFQ.jpg)
]

--
exclude: true

- improvements in feature detection and extraction

.img-right[
![](../inst/images/IonStar_MQ_PD.jpg)
]

--
exclude: true

- a zoo of data <br/> transformation, pretreatment, imputation methods

.img-right[
![](../inst/images/LFQ_Improvement.jpg)
]


--
exclude: true

- improvements in fold change estimation

.img-right[
![](../inst/images/Ropeca.png)
]



.footnote[
[Extending the Limits of Quantitative Proteome](https://www.mcponline.org/content/14/5/1400);
[Ionstar](https://www.pnas.org/content/115/21/E4767);
[Simultaneous Improvement in the Precision...](https://www.mcponline.org/content/18/8/1683);
[Ropeca](https://www.nature.com/articles/s41598-017-05949-y)
]

---

# Overview

- Scientific method
- Causality and Bradford Hill criteria
- Study Types
- Randomized Controlled Trial
- Types of Bias
- Confounders
- Ethical Considerations
- Sample size estimation
- Experimental Designs

---

# Scientific Method

1. __Question__
2. __Hypothesis__
3. __Experiment__ <br/> ordered investigation that attempts to prove or disprove a hypothesis
  - must show if hypothesis is supported or not.
  - results must be measurable
  - experiment must be repeatable
4. __Observation__ <br/> make observations about results of experiment
5. __Analysis__ <br/> run test
6. __Conclusion__ <br/> significant result


---

# Question - Causality

.pull-left[
Assess whether a particular __agent__ 

caused or influenced a particular __outcome__ 
]

.right-plot[
![](../inst/images/CausalNetworkSignalTransduction.png)
]


---
exclude: true

# Causality - How to prove cause and effect?

.right-plot[
![](../inst/images/BuehlmanCausality.png)
]

.footnote[[Peter Buehlmann "Invariance, Causality and Robustness"](https://arxiv.org/pdf/1812.08233.pdf)]

---

# Causality - Bradford-Hill Criteria


1.  __Strength of association__ – (effect size) the greater the effect compared with those not
exposed to the agent the more plausible is the association
2. __Consistency__ – (reproducibility) does it happen in other groups of people – both men and
women, different countries
3. __Specificity__ – no other likely explanations
4. __Temporality__ – effect follows cause, and if expected delay, effect must occur after that delay
5.  __Biological gradient__ – the stronger the agent the greater the effect
6.  __Plausibility__ – is there a possible biological mechanism that could explain the effect
7. __Coherence__ – do different types of study result in similar conclusions – e.g., controlled trials and observational studies
8. __Experiment__ "Occasionally it is possible to appeal to experimental evidence".
<!-- 9. Analogous results found elsewhere – do similar agents have similar results?-->

.footnote[
Sir Austin Bradford Hill CBE FRS was an English epidemiologist and statistician, pioneered the randomized clinical trial (use of streptomycin in treating tuberculosis) and, together with Richard Doll, demonstrated the connection between cigarette smoking and lung cancer (case-control study).
]

---

# Bradford-Hill Criteria

.pull-left[Plausibility<br/>
![](../inst/images/BH_Plausibility.png)]

.pull-right[Specificity<br/>
![](../inst/images/BH_Specificity.png)]

.footnote[[Explaining Hill Criteria using xkcd](https://www.kdnuggets.com/2017/02/hill-data-scientist-xkcd-story.html)<br/>
[The Bradford Hill Criteria Don't Hold Up](https://lesslikely.com/statistics/bradford-hill-criteria-dont-hold/)
]


---

# Question - Causality - Bradford-Hill Criteria

- Does establishing all Bradford-Hill criteria prove cause and effect?
- Which Bradford-Hill criteria do you aim to meet in your study?


- Protein Quantification 
  - Strength of association : Control, Treatment $5 \mu g$, Treatment $10 \mu g$
  - Consistency : Different Genetic backgrounds, Control and Treatment (__it depends__)
  - Temporality : Time course data
  - Specificity : ?



---

# Question - Causality

.pull-left[
- Can we infer causal models directly from data?
- Would you prefer?
  - to have dataset with $4000$ proteins and $2$ conditions
  - a dataset with $400$ proteins and more than $>100$ conditions?
]

.right-plot[
![](../inst/images/Causality_fromData.jpg)

]
.footnote[[CausalDisco](https://github.com/annennenne/causalDisco/blob/master/slides/causaldisco_ahp_user2019.pdf)
an overview of methods (implemented in R) to infer causal networks from data <br/>

Judea Pearl "The Book of Why: The New Science of Cause and Effect"<br/>

]



---

# Study Types

“Test your servants for ten days: Give us nothing but vegetables to eat and water to drink. Then compare our appearance with that of the young men who eat the royal food, and decide what to do with us based on how we look.”

Bible (see Daniel 1:1–16).

Bregman, Rutger. Utopia for Realists (p. 206). Bloomsbury Publishing. Kindle Edition. 

---

# Study Types 

.pull-left[
## Observational study
- Case-control study -  individuals with a specific characteristic (disease and similar individuals without disease)
- Cross-sectional study - aim to provide data on the entire population under study.
- Longitudinal study - repeated observations of the same variables (e.g., people) over short or long periods of time. They can also be structured as longitudinal __randomized experiments__, e.g. Mice aging.
]

.pull-right[
## Experimental Intervention
- randomized controlled trials  <br/>
(randomize subjects into two groups, placebo and treatment group)
]


---

# Study Types - Case control study
.image-70[
![](../inst/images/Study_Type_Case_Control.png)
]

---

# Study Types - Pros and cons

.pull-left[
## Observational study
pros:
- May require less resources
- Less ethical considerations (e.g. smokers)
- Good if outcome of interest is rare

cons:
- difficult to determine causality
- no randomization or blinding
- The exposure status is not determined by the researcher
]

.pull-right[
## Experimental Intervention
pros:
- More validity
- Can determine causality
- Randomized and blinded


cons:
- may require more resources
- Ethical concerns for certain exposures
- Difficult if outcome studied is rare<br/> (e.g. Vaccination)
]

---

exclude: true

# Randomized controlled trial

"This year’s (2019) Laureates have introduced<br/>
a new approach to obtaining reliable answers<br/>
about the best ways to fight global poverty. 

In brief, it involves __dividing this issue into<br/>
smaller, more manageable, questions__ – for example,<br/>
the most effective interventions for improving educational<br/>
outcomes or child health. 

They have shown that these smaller, more precise,<br/>
questions are often best answered via carefully<br/>
__designed experiments__<br/>
among the people who are most affected."


.img-right[
![](../inst/images/Nobel2019.png)
]




---
layout: false

# Randomized controlled trial - Randomization

A randomized controlled trial is a type of scientific experiment that aims to reduce certain sources of __bias__ when testing the effectiveness of new treatments.

- __selection bias__ 
    - sample obtained is _not representative_ of the population intended to be analyzed.
- __allocation bias__ 
    - _systematic difference_ in how participants are assigned to treatment groups and comparison groups
    - __Randomly allocate subjects to two or more groups__


.footnote[

https://en.wikipedia.org/wiki/Randomized_controlled_trial<br/>
https://en.wikipedia.org/wiki/Bias]

---

# Bias

- Confirmation bias,<br/> tendency to favor information that confirm hypothesis $^{\star}$

.img-right[
![](../inst/images/Man_In_The_Moon_1.png)
]


--

- Funding bias,<br/> bias relative to the commercial interests of a study's <br/> financial sponsor
.img-right[
![](../inst/images/Man_In_The_Moon_2.png)
]
--

- Publication bias,<br/> bias towards publication of certain experimental results. $^{\star\star}$
  
.img-right[
![](../inst/images/Man_In_The_Moon_3.png)
]

.footnote[
$^\star$ Do you examine an experiment for a technical problem which <br/>
fits your hypothesis? </br>
$^{\star\star}$ Over-interpretation of improvements of new methods.

]

---

# Randomized controlled trial - Blinding

 - Information which may influence the participants<br/>
 is withheld until after the experiment is completed
 - A blind can be imposed on any participant<br/>
 of an experiment, including<br/> 
 __subjects, researchers, technicians,<br> data analysts, and evaluators__

- In clinical Trials double blind trials should <br/>
be used where possible
  - __Single blind__ – either patient or evaluator blind.
  - __Double blind__ – both patient and evaluator blind

.img-right[![](../inst/images/blind_trials.png)]


---

# Confounders


Correlation does not imply causation but causation may imply correlation.

__Confounder__ - is a variable that influences both the dependent variable and independent variable, causing a spurious association.

__Reichenbach's common cause principle:__ <br/>
A correlation occurs due to one of the three possible mechanisms
.img-small[
![](../inst/images/Causality_Mechanisms_3.png)
]

.footnote[[Mediators, confounders, colliders – a crash course in causal inference](https://theoreticalecology.wordpress.com/2019/04/14/mediators-confounders-colliders-a-crash-course-in-causal-inference/)]

<!--
.img-right[
![](../inst/images/Confounding_Wiki.png)
]
-->

---
layout: false

# Controlling for Confounders

- Randomize over biological and <br/>  technical co-variates. <br/> 
  e.g. run Id, age.
- Avoid batch effects:
    - process all samples in parallel
- block confounders <br/> 
_complete block design_, i.e.,<br/> 
all treatments are present in each batch<br/>
in equal numbers.

.img-right[
![How to avoid](../inst/images/BatchEffect.png)
How to avoid confounding by batch
]


.footnote[
https://doi.org/10.1021/pr8010099]
https://doi.org/10.1021/acs.jproteome.0c00536]
]

---

# Controlling for Confounders

## Queue Generator

Use block random queue when processing samples to _block_ for changes in the chromatographic column over time.

__Example:__

\# of samples in each condition 3 x A, 3 x B, 2 x C, 2 x D. <br/>
Blocks :  ABCD, BCDA, BA <br/>


.footnote[http://fgcz-ms-shiny.uzh.ch:8080/queue_generator10/]

---

# Confounders - Reporting

Document possible co-variates, e.g.,

.pull-left[

- Human subjects:
  - age
  - bmi 
  - gender 
  - ...
]

.pull-right[
-  Biochemical/Technical: 
   - batch 
   - run Id
   - instrument
   - ...
]

- Report your research so that it can be reviewed, reproduced and analysed.
- Do not over-interpret your results.


.footnote[
[Over-interpretation and misreporting of prognostic factor
studies in oncology: a systematic review](https://www.nature.com/articles/s41416-018-0305-5.pdf)<br/>
http://www.equator-network.org/<br/>
https://www.ncbi.nlm.nih.gov/pubmed/29873743
]



---


# Ethical considerations

- It is agreed that it is __unethical__ _to conduct research which is badly planned or
executed_.

-  It is unethical to perform a trial which:
  - has _many more subjects_ than are needed to reach a conclusion.
  - has little prospect of reaching any conclusion, <br/> e.g. because 
  of _insufficient numbers of subjects_ (or some other aspect of poor design)

- The local ethics committee has discretion on how it will supervise __non-interventional__ studies
  -  US - Institutional Review Board (IRB)
  -  EU - ethics committees

[Declaration of Helsinki (1964+amendments))](https://www.wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/)

---

# Types of error


A __type I error__ (false positive) occurs when<br/> the null hypothesis (H0) is true, but is rejected.<br/> 
The _type I error rate_ or __significance level__ (p-Value)<br/> is the probability of rejecting the<br/> 
null hypothesis given that it is true.


A __type II error__ (false negative) occurs when<br/> 
the null hypothesis is false,<br/>
but erroneously fails to be rejected. <br/>
The _the type II error rate_ is denoted by the Greek letter $\beta$<br/>
and is related to the __power of a test__ (which equals $1−\beta$).

For a given test, the only way to reduce both error rates<br/> 
is to __increase the sample size__, and this may not be feasible.

.img-right[
![](../inst/images/hl_nullhypo_errors.png)
]


---

# Sample size calculation


.pull-left[

Run pilot experiment and measure the coefficient of variation (CV) or <br>
$\sigma^2$ of replicates:

- technical
- _biochemical_
- __biological__
]



.pull-right[
- _biological variance >> bio-chem+tech variance_<br/> 
  - Only provide biological replicates
- _bio-chem+tech variance >> biological variance_<br/>
  - __improve sample handling and preparation__
  - choose different technology
  - buy better instrument
]

.footnote[measure 3 tech replicates, 3 tech+bio-chem replicates, 3 tech+bio-chem+biological replicates]

---

# Sample size calculation

.footnote[Top - greater standard deviation requires larger sample sizes, Bottom - smaller effect size requires larger sample sizes]

.pull-left[
For each statistical test,<br/> 
there exists a unique relation between:

- desired smallest detectable effect size $\mu$
- sample variance $\sigma^2$
- sample size $N$
- critical p-value $p_0$
- statistical power

]

.right-plot[
```{r echo=FALSE}
sd <- seq(0.5, 2, by = .001)
dd <- power.t.test(delta = 2, sd = 1, sig.level = 0.05, power = 0.8)
powersd <- function(sd, delta = 1, sig.level = 0.05, power = 0.8){
  ceiling(power.t.test(delta = 2, sd = sd, sig.level = sig.level, power = power)$n)
}

ressd <- sapply(sd, powersd)
power_delta <- function(delta, sd = 1, sig.level = 0.05, power = 0.8){
  ceiling(power.t.test(delta = delta, sd = sd, sig.level = sig.level, power = power)$n)
}

delta <- seq(0.5,6, by = 0.001)
resdelta <- sapply(delta, power_delta)
plot(sd, ressd, ylab = "N", type = "l", main = "mu=1, p=0.05, power = 0.8")
plot(delta, resdelta, xlab = "mu", ylab = "N", type = "l", log = "xy", main = "sd=1, p = 0.05, power = 0.8")

```
]

---

# Experimental Design

The key technical issue is whether comparisons are made __between__ or __within__ subjects.


.pull-left[
Between

- Parallel Group Design <br/> k - groups, $n_i$ patients in group $i$ receive treatment $i$
- Factorial Design <br/>  - more than one factor. combining treatments, e.g. A and B to same patient.
]

.pull-right[
Within (repeated/paired)

- In series design <br/> each patient all $k$ treatments in same order
- crossover design <br/> each patient  all $k$ treatments in different order
]

Are combinations of both possible?

.footnote[Ronald Fisher (1890 - 1962) "The Arrangement of Field Experiments" (1926) and "The Design of Experiments" (1935).]

---

# Factorial Design vs Parallel group

.pull-left[
Parallel (one factor)

- drug A
- drug B
- plac
]

.pull-right[
Factorial (2 or more factors)

- Factor A
  - drug A
  - plac A
- Factor B
  - drug B
  - plac B
]

40 patients, Placebo, drug A and drug B.
How would you allocate these patients?


.footnote[Ronald Fisher pioneered the use of factorial experiments instead of the one-factor-at-a-time method.]

---

# Factorial Design vs Parallel group

.pull-left[
Parallel (one factor)

- drug A (13)
- drug B (13)
- plac (14)

Compare:
- 13 drug A vs 14 plac
- 13 drug B vs 14 plac
]

.pull-right[
Factorial (2 or more factors)

- drug A + drug B (10)
- plac A + drug B (10)
- drug A + plac B (10)
- plac A + plac B (10)

Compare:
- 20 drug A vs 20 plac A
- 20 drug B vs 20 plac B 
]


---
layout: false

# Factorial Design - Interactions

Factorial Designs are efficient at evaluating<br/>
the effects and possible interactions of<br/> 
several factors (independent variables).



.footnote[https://en.wikipedia.org/wiki/Design_of_experiments]

--

- No interaction
.img-right[
![](../inst/images/TypesOfInteractions_NO.png)


[Medical Statistics - University of Sheffield]
]


--

- Quantitative interaction

.img-right[
![](../inst/images/TypesOfInteractions_Quanti.png)
]


--

- Qualitative interaction

.img-right[
![](../inst/images/TypesOfInteractions_Quali.png)
]



---
exclude: true

# All possible interactions


- 1 = there was a main effect for IV1.
- ~1 = there was not a main effect for IV1
- 2 = there was a main effect for IV2
- ~2 = there was not a main effect of IV2
- 1x2 = there was an interaction 
- ~1x2 = there was not an interaction

.img-right[
![](../inst/images/allInteractions2x2.png)
]

.footnote[https://crumplab.github.io/statistics/more-on-factorial-designs.html]

---

# Summary

- Did you observe bias in your research?
- What is the type of your study?
- What are potential confounders?
- Which Bradford Hill Criteria are you examining and how?
- What is the Design of your experiment?


---
